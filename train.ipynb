{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import glob\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import *\n",
    "from train import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = CropDataset('./data/crop_set/train.hdf5')\n",
    "valid = CropDataset('./data/crop_set/valid.hdf5')\n",
    "test = CropDataset('./data/crop_set/test.hdf5')\n",
    "\n",
    "train_loader = DataLoader(dataset=train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid, batch_size=len(valid), shuffle=True)\n",
    "test_loader = DataLoader(dataset=test, batch_size=len(test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_channels=5, n_classes=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import UNet\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from dice_loss import dice_coeff\n",
    "\n",
    "inter = None\n",
    "\n",
    "def train_model(model, \n",
    "          optimizer, \n",
    "          loss_fn, \n",
    "          device, \n",
    "          epochs, \n",
    "          train_loader, \n",
    "          valid_loader):\n",
    "    \n",
    "    train_loss = []\n",
    "    train_dice = []\n",
    "    vaild_loss = []\n",
    "    valid_dice = []\n",
    "    bar = tqdm(range(epochs), position=0)\n",
    "    \n",
    "    for epoch in bar:\n",
    "        model.train()\n",
    "        train_loss_e = []\n",
    "        train_dice_e = []\n",
    "        \n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            samples, labels = batch\n",
    "            samples, labels = samples.to(device), labels.to(device)\n",
    "            \n",
    "            preds = pred_step(samples, model)\n",
    "            loss, dice = eval_step(preds, labels, loss_fn, True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_e.append(loss.item())\n",
    "            print(loss.item())\n",
    "            train_dice_e.append(dice)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, batch in enumerate(valid_loader):\n",
    "            with torch.no_grad():\n",
    "                samples, labels = batch\n",
    "                samples, labels = samples.to(device), labels.to(device)\n",
    "                \n",
    "                preds = pred_step(samples, model)\n",
    "                loss, dice = eval_step(preds, labels, loss_fn, True)\n",
    "                \n",
    "                vaild_loss.append(loss.item())\n",
    "                valid_dice.append(dice)\n",
    "              \n",
    "        train_loss.append(np.mean(train_loss_e))\n",
    "        train_dice.append(np.mean(train_dice_e))      \n",
    "        \n",
    "    return model, {\n",
    "        'train_loss': train_loss,\n",
    "        'valid_loss': vaild_loss,\n",
    "        'train_dice': train_dice,\n",
    "        'valid_dice': valid_dice\n",
    "        }      \n",
    "        \n",
    "\n",
    "def pred_step(samples, model):\n",
    "    preds = model.forward(samples)\n",
    "    return preds\n",
    "\n",
    "def eval_step(preds, labels, loss_fn, compute_dice=False):\n",
    "    loss = loss_fn(preds, labels)\n",
    "    \n",
    "    if compute_dice:\n",
    "        dice = dice_coeff(preds, labels)\n",
    "        return loss, dice\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, results = train_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    'cpu',\n",
    "    EPOCHS,\n",
    "    train_loader,\n",
    "    valid_loader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
